{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c4609a-bcb8-41df-91dc-0e61ae540748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "libs_path = os.path.abspath(os.path.join(current_dir, \"..\", \"libs\"))\n",
    "if libs_path not in sys.path:\n",
    "    sys.path.append(libs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bb4681-62ff-482a-af3e-97048d8b25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "pd.set_option('display.precision', 3)\n",
    "import data_processing as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cfeb764-a97c-4d6b-8e84-e43461cf904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049ab734efed4953ad360709991c4661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Датасеты:', layout=Layout(width='500px'), options={'.ipynb_checkpoints': 'E:\\\\stud…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a89f42bcac64d9aa26a7a8d2aeb0a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='ОК', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377619d057ed42da86f947d942ce82a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res=dp.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6f9f6c-ec1f-49d0-a470-c1d25e34e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for fn in res.options:\n",
    "\n",
    "    if res.options[fn] not in res.value:\n",
    "        continue\n",
    "    dataset = dp.Dataset(pd.read_csv(res.options[fn]), name=fn)\n",
    "\n",
    "    dataset.target_features = [\"Cover_Type\"]\n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f125e4-c3e1-4884-9088-9c5e3cde1987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_enhanced.csv\n",
      "df_selected_features.csv\n",
      "V4_classification_lr3.csv\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    print(d.name)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37295a-6556-4a5e-b70e-feb1920f7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Масштабирование исходного набора данных (df_enhanced)\n",
    "\n",
    "# Определяем числовые и бинарные/OHE признаки\n",
    "# Исходные числовые признаки (включая добавленные)\n",
    "numerical_cols_for_scaling_original = [col for col in df_enhanced.columns if col in numerical_features_enhanced]\n",
    "# Бинарные/OHE признаки, которые не нужно масштабировать\n",
    "binary_ohe_cols_original = [col for col in df_enhanced.columns if col.startswith('Wilderness_Area') or col.startswith('Soil_Type')]\n",
    "\n",
    "# Создаем препроцессор для масштабирования числовых признаков\n",
    "preprocessor_original = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_cols_for_scaling_original)],\n",
    "    remainder='passthrough' # Оставляем остальные признаки как есть (бинарные)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d99ef1-63d8-48ae-945e-9b80d8ce0a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Применяем масштабирование к исходному набору данных (без целевой переменной)\n",
    "X_original_scaled = preprocessor_original.fit_transform(df_enhanced.drop('Cover_Type', axis=1))\n",
    "\n",
    "# Получаем названия колонок после преобразования (это сложнее, так как ColumnTransformer меняет порядок)\n",
    "# Признаки из numerical_cols_for_scaling_original будут первыми, затем остальные.\n",
    "# Остальные признаки будут в том же порядке, что и в df_enhanced.drop('Cover_Type', axis=1),\n",
    "# но исключая numerical_cols_for_scaling_original.\n",
    "\n",
    "# Получаем названия колонок после transform для preprocessor_original\n",
    "# Сначала идут масштабированные числовые колонки\n",
    "scaled_feature_names_original = numerical_cols_for_scaling_original\n",
    "# Затем идут колонки, которые не были преобразованы (remainder='passthrough')\n",
    "passthrough_feature_names_original = [col for col in df_enhanced.drop('Cover_Type', axis=1).columns if col not in numerical_cols_for_scaling_original]\n",
    "\n",
    "all_scaled_feature_names_original = scaled_feature_names_original + passthrough_feature_names_original\n",
    "\n",
    "# Создаем DataFrame с масштабированными данными\n",
    "df_original_scaled = pd.DataFrame(X_original_scaled, columns=all_scaled_feature_names_original)\n",
    "df_original_scaled['Cover_Type'] = df_enhanced['Cover_Type'].values # Добавляем целевой признак\n",
    "print(\"\\n--- Исходный набор данных после Min-Max масштабирования ---\")\n",
    "print(df_original_scaled.head())\n",
    "\n",
    "\n",
    "# 2. Масштабирование сформированного набора данных (df_selected_features)\n",
    "\n",
    "# Определяем числовые и бинарные/OHE признаки в df_selected_features\n",
    "numerical_cols_for_scaling_selected = [col for col in df_selected_features.columns if col in numerical_features_enhanced] # Используем расширенный список численных признаков\n",
    "binary_ohe_cols_selected = [col for col in df_selected_features.columns if (col.startswith('Wilderness_Area') or col.startswith('Soil_Type')) and col in df_selected_features.columns]\n",
    "\n",
    "\n",
    "preprocessor_selected = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_cols_for_scaling_selected)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Применяем масштабирование к сформированному набору данных (без целевой переменной)\n",
    "X_selected_scaled = preprocessor_selected.fit_transform(df_selected_features.drop('Cover_Type', axis=1))\n",
    "\n",
    "# Получаем названия колонок после transform для preprocessor_selected\n",
    "scaled_feature_names_selected = numerical_cols_for_scaling_selected\n",
    "passthrough_feature_names_selected = [col for col in df_selected_features.drop('Cover_Type', axis=1).columns if col not in numerical_cols_for_scaling_selected]\n",
    "\n",
    "all_scaled_feature_names_selected = scaled_feature_names_selected + passthrough_feature_names_selected\n",
    "\n",
    "# Создаем DataFrame с масштабированными данными\n",
    "df_selected_features_scaled = pd.DataFrame(X_selected_scaled, columns=all_scaled_feature_names_selected)\n",
    "df_selected_features_scaled['Cover_Type'] = df_selected_features['Cover_Type'].values # Добавляем целевой признак\n",
    "print(\"\\n--- Сформированный набор данных после Min-Max масштабирования ---\")\n",
    "print(df_selected_features_scaled.head())\n",
    "\n",
    "# Сохраняем исходные данные без изменений для анализа (они уже в df_enhanced)\n",
    "# df_original = df_enhanced.copy() - не нужно, df_enhanced уже есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66b73d-ae7d-4ca4-ae09-dff46476aa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9cd19-6689-415f-8eb8-77adb9665889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbb2853b-003d-4599-b949-5531421d7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_features.to_csv(\"../datasets/df_selected_features.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
