{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c4609a-bcb8-41df-91dc-0e61ae540748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "libs_path = os.path.abspath(os.path.join(current_dir, \"..\", \"libs\"))\n",
    "if libs_path not in sys.path:\n",
    "    sys.path.append(libs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bb4681-62ff-482a-af3e-97048d8b25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "pd.set_option('display.precision', 3)\n",
    "import data_processing as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cfeb764-a97c-4d6b-8e84-e43461cf904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a946a25cd4e84c47aa21645374ebd8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Датасеты:', layout=Layout(width='500px'), options={'.ipynb_checkpoints': 'E:\\\\stud…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130056f486d44c26a83bf82ff74d8a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='ОК', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc622d7643b4b7392e26ed6df27e7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res=dp.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6f9f6c-ec1f-49d0-a470-c1d25e34e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for fn in res.options:\n",
    "\n",
    "    if res.options[fn] not in res.value:\n",
    "        continue\n",
    "    dataset = dp.Dataset(pd.read_csv(res.options[fn]), name=fn)\n",
    "\n",
    "    dataset.target_features = [\"Cover_Type\"]\n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f125e4-c3e1-4884-9088-9c5e3cde1987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_enhanced.csv_selected_features.csv_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    print(d.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48baf61-c156-4751-8f9c-cb9defe73db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Input, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "def create_mlp_model(input_shape, num_classes, optimizer='adam', learning_rate=0.001, dense_units=[128, 64]):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_shape,)))\n",
    "    for du in dense_units:\n",
    "        model.add(Dense(du, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    if optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_1d_cnn_model(input_shape, num_classes, filters=[128, 256],\n",
    "                         kernel_size=3, pool_size=2, use_batch_norm=True, dense_units=[128, 64],\n",
    "                         optimizer='adam', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_shape, 1))) # input_shape уже должен быть (num_features, 1)\n",
    "    i=0\n",
    "    for f in filters:\n",
    "        model.add(Conv1D(filters=f, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        # Добавляем MaxPooling1D, если есть смысл и достаточное количество признаков\n",
    "        if input_shape > pool_size * (i + 1) : # Убедимся, что размерность не станет слишком маленькой\n",
    "            model.add(MaxPooling1D(pool_size=pool_size))\n",
    "        else:\n",
    "            # Если MaxPooling1D может сделать размерность 0, пропускаем его\n",
    "            # или можно настроить логику по-другому, например, убрать padding='same'\n",
    "            # и добавить его только на первом слое\n",
    "            pass # Пропускаем MaxPooling, если он приведет к 0 размерности\n",
    "        i+=1\n",
    "    model.add(Flatten())\n",
    "    for du in dense_units:\n",
    "        model.add(Dense(du, activation='relu'))\n",
    "        if use_batch_norm: # Можно добавить BatchNormalization и здесь, но это опционально\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Выбор оптимизатора\n",
    "    if optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = Adam(learning_rate=learning_rate) # Default\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065b563d-2e70-442a-a044-0a45740467da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def all_combinations(args_dict):\n",
    "    # Получаем имена аргументов и их возможные значения\n",
    "    arg_names = args_dict.keys()\n",
    "    values = args_dict.values()\n",
    "    res = []\n",
    "    # Перебираем все комбинации значений\n",
    "    for combination in product(*values):\n",
    "        # Создаем словарь с аргументами\n",
    "        kwargs = dict(zip(arg_names, combination))\n",
    "        # Вызываем функцию с текущей комбинацией\n",
    "        res.append(kwargs)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b26735-5ed8-41b7-beac-fad1278fba97",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "df_enhanced.csv_selected_features.csv_scaled.csv;\n",
    "\n",
    "{'input_shape': 12, 'num_classes': 7, 'optimizer': 'adam', 'learning_rate': 0.0001, 'dense_units': [128, 64, 32], 'kernel_size': 3, 'pool_size': 1, 'use_batch_norm': True, 'filters': [32, 64, 128, 256]};train; acc= 0.8942210110615779;\n",
    "train; bal_acc= 0.8626425709899458;\n",
    "train; f1_macro= 0.8451931067676445;\n",
    "train; f1_weighted= 0.8947763834199238;\n",
    "train; classification_report=               precision    recall  f1-score   support\n",
    "\n",
    "     Class 1       0.85      0.91      0.88    117344\n",
    "     Class 2       0.94      0.89      0.91    186357\n",
    "     Class 3       0.89      0.88      0.89     19706\n",
    "     Class 4       0.70      0.85      0.76      1587\n",
    "     Class 5       0.71      0.79      0.75      5827\n",
    "     Class 6       0.83      0.80      0.82     10722\n",
    "     Class 7       0.90      0.91      0.91     12204\n",
    "\n",
    "    accuracy                           0.89    353747\n",
    "   macro avg       0.83      0.86      0.85    353747\n",
    "weighted avg       0.90      0.89      0.89    353747\n",
    ";\n",
    "test; acc= 0.8873465187838252;\n",
    "test; bal_acc= 0.8519674120968215;\n",
    "test; f1_macro= 0.8334169192106298;\n",
    "test; f1_weighted= 0.8880086097095863;\n",
    "test; classification_report=               precision    recall  f1-score   support\n",
    "\n",
    "     Class 1       0.85      0.90      0.87     33391\n",
    "     Class 2       0.93      0.89      0.91     53281\n",
    "     Class 3       0.88      0.88      0.88      5779\n",
    "     Class 4       0.69      0.82      0.75       449\n",
    "     Class 5       0.67      0.77      0.72      1608\n",
    "     Class 6       0.81      0.79      0.80      3101\n",
    "     Class 7       0.90      0.91      0.90      3462\n",
    "\n",
    "    accuracy                           0.89    101071\n",
    "   macro avg       0.82      0.85      0.83    101071\n",
    "weighted avg       0.89      0.89      0.89    101071\n",
    ";\n",
    "valid; acc= 0.8885349058097198;\n",
    "valid; bal_acc= 0.8507051994173384;\n",
    "valid; f1_macro= 0.831589703069928;\n",
    "valid; f1_weighted= 0.8892020492955838;\n",
    "valid; classification_report=               precision    recall  f1-score   support\n",
    "\n",
    "     Class 1       0.85      0.90      0.88     16938\n",
    "     Class 2       0.93      0.89      0.91     26629\n",
    "     Class 3       0.87      0.87      0.87      2749\n",
    "     Class 4       0.70      0.83      0.76       237\n",
    "     Class 5       0.65      0.77      0.71       780\n",
    "     Class 6       0.81      0.78      0.80      1480\n",
    "     Class 7       0.90      0.90      0.90      1723\n",
    "\n",
    "    accuracy                           0.89     50536\n",
    "   macro avg       0.82      0.85      0.83     50536\n",
    "weighted avg       0.89      0.89      0.89     50536\n",
    ";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37295a-6556-4a5e-b70e-feb1920f7376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\AppData\\Local\\Temp\\ipykernel_24064\\2792730981.py:11: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  num_classes = int(d[d.target_features].nunique()) # ИСПРАВЛЕНИЕ: Количество уникальных классов\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0 {'input_shape': 12, 'num_classes': 7, 'optimizer': 'adam', 'learning_rate': 0.0001, 'dense_units': [128, 64, 32], 'kernel_size': 3, 'pool_size': 1, 'use_batch_norm': True, 'filters': [16, 32, 64, 128, 256]}\n",
      "Epoch 1/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.7156 - loss: 0.9563\n",
      "Epoch 2/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.7870 - loss: 0.5419\n",
      "Epoch 3/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.8081 - loss: 0.4644\n",
      "Epoch 4/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.8201 - loss: 0.4275\n",
      "Epoch 5/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.8300 - loss: 0.4002\n",
      "Epoch 6/30\n",
      "\u001b[1m 65"
     ]
    }
   ],
   "source": [
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True, verbose=0)\n",
    "\n",
    "for d in datasets:\n",
    "    d.target_features\n",
    "    temp_name = d.name\n",
    "    num_classes = int(d[d.target_features].nunique()) # ИСПРАВЛЕНИЕ: Количество уникальных классов\n",
    "    assert num_classes == 7\n",
    "    temp = []\n",
    "    for i in range(num_classes):\n",
    "        temp.append(d.target_features[0] + f\"_{i}\")\n",
    "    #d.target_features = \n",
    "    d[temp] = to_categorical(d[d.target_features].values - 1, num_classes=7) # Эта строка остается\n",
    "    d = d.drop(d.target_features, axis=1)\n",
    "    d = dp.Dataset(d)\n",
    "    d.target_features = temp\n",
    "    d.name = temp_name\n",
    "    \n",
    "    d.split_data(random_state=1337)\n",
    "\n",
    "    all_models = []\n",
    "    params = {\"optimizer\" : ['adam'], \"learning_rate\" : [0.0001], \"dense_units\":[[128, 64, 32]]}\n",
    "    params_1d_cnn = {\"kernel_size\" : [3], \"pool_size\": [1], \"use_batch_norm\": [True], \"filters\":[[16, 32, 64, 128, 256]]}\n",
    "    params_mlp = {}\n",
    "    params_default = {\"input_shape\": [d.shape[1] - num_classes], \"num_classes\" : [num_classes]}\n",
    "    \n",
    "    \n",
    "    mlp_comb = all_combinations({**params_default, **params, **params_mlp})\n",
    "    cnn_comb = all_combinations({**params_default, **params, **params_1d_cnn})\n",
    "    #print(len(mlp_comb))\n",
    "    print(len(cnn_comb))\n",
    "\n",
    "    iii = 0\n",
    "    #for el in mlp_comb:\n",
    "    for el in cnn_comb:\n",
    "\n",
    "        print(iii, el)\n",
    "        iii+=1\n",
    "        #model = create_mlp_model(**el)\n",
    "        model = create_1d_cnn_model(**el)\n",
    "\n",
    "        history = model.fit(d.X_train.values, d.Y_train.values, epochs=30, batch_size=256, callbacks=[early_stopping])\n",
    "        with open('results_final2.txt', 'a', encoding='utf-8') as f:\n",
    "            f.write(f\"\\n\\n{d.name}; {el};\")\n",
    "\n",
    "        \n",
    "\n",
    "        Y_train_real = model.predict(d.X_train.values, verbose=0)\n",
    "        Y_test_real = model.predict(d.X_test.values, verbose=0)\n",
    "        Y_valid_real = model.predict(d.X_valid.values, verbose=0)\n",
    "       # print(np.isnan(Y_train_real).any())\n",
    "       # print(np.isnan(Y_test_real).any())\n",
    "       # print(np.isnan(Y_valid_real).any())\n",
    "\n",
    "        AAA = [[np.argmax(Y_train_real, axis=1), np.argmax(d.Y_train.values, axis=1), \"train\"], [np.argmax(Y_test_real, axis=1), np.argmax(d.Y_test.values, axis=1), \"test\"], [np.argmax(Y_valid_real, axis=1), np.argmax(d.Y_valid.values, axis=1), \"valid\"]]\n",
    "        with open('results_final2.txt', 'a', encoding='utf-8') as f:\n",
    "            for viborka in AAA:\n",
    "                try:\n",
    "                    #print(type(viborka[0]), type(viborka[1]))\n",
    "                    #print(accuracy_score(viborka[0], viborka[1]))\n",
    "                    f.write(f\"{viborka[2]}; acc= {accuracy_score(viborka[0], viborka[1])};\\n\")\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    f.write(f\"{viborka[2]}; acc= accuracy_score_error;\\n\")\n",
    "                try:\n",
    "\n",
    "                    f.write(f\"{viborka[2]}; bal_acc= {balanced_accuracy_score(viborka[0], viborka[1])};\\n\")\n",
    "                except:\n",
    "                    f.write(f\"{viborka[2]}; bal_acc= balanced_accuracy_score_error;\\n\")\n",
    "\n",
    "                try:\n",
    "\n",
    "                    f.write(f\"{viborka[2]}; f1_macro= {f1_score(viborka[0], viborka[1], average='macro', zero_division=0)};\\n\")\n",
    "                except:\n",
    "                    f.write(f\"{viborka[2]}; f1_macro= f1_score_error;\\n\")\n",
    "\n",
    "                try:\n",
    "\n",
    "                    f.write(f\"{viborka[2]}; f1_weighted= {f1_score(viborka[0], viborka[1], average='weighted', zero_division=0)};\\n\")\n",
    "                except:\n",
    "                    f.write(f\"{viborka[2]}; f1_weighted= f1_score_error;\\n\")\n",
    "\n",
    "                try:\n",
    "                    f.write(f\"{viborka[2]}; classification_report= {classification_report(viborka[0], viborka[1], target_names=[f'Class {i+1}' for i in range(num_classes)], zero_division=0)};\\n\")\n",
    "                except:\n",
    "                    f.write(f\"{viborka[2]}; classification_report= classification_report_error;\\n\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22633f45-0da3-49c2-804c-c19577a55925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d99ef1-63d8-48ae-945e-9b80d8ce0a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc66b73d-ae7d-4ca4-ae09-dff46476aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9cd19-6689-415f-8eb8-77adb9665889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2853b-003d-4599-b949-5531421d7090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152e607-ccef-4391-9445-8977d7b6a1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
